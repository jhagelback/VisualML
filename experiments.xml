<?xml version="1.0"?>
<Experiments>
    <!--
        Linear Classifiers
        
        The following parameters are available:
        
        <Classifier>Linear</Classifier>                         Linear
        <TrainingData>data/demo.csv</TrainingData>              Path to training dataset
        <TestData></TestData>                                   Path to test dataset (or empty if no test data is used)
        <Iterations>10</Iterations>                             Training iterations (default is 200)
        <LearningRate>1.0</LearningRate>                        Learning rate (default is 1.0)
        <UseRegularization>true</UseRegularization>             Sets if regularization shall be used (default is true)
        <RegularizationStrength>0.01</RegularizationStrength>   Sets regularization strength (default is 0.01)
        <Normalization>0:1</Normalization>                      Lower and upper bound for normalized values
        <BatchSize>100</BatchSize>                              Size of batches for batch training. If not set, batch training isn't used
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="l_demo">
        <!-- Training set: 100.00% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <Iterations>10</Iterations>
        <LearningRate>1.0</LearningRate>
    </Experiment>
    <Experiment id="l_spiral">
        <!-- Training set: 54.67% -->
        <!-- Cross-validation: 50.67% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <Iterations>200</Iterations>
        <LearningRate>0.1</LearningRate>
    </Experiment>
    <Experiment id="l_circle">
        <!-- Training set: 68.60% -->
        <!-- Cross-validation: 68.60% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <Iterations>20</Iterations>
        <LearningRate>1.0</LearningRate>
    </Experiment>
    <Experiment id="l_iris">
        <!-- Training set: 98.67% -->
        <!-- Cross-validation: 98.00% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.2</LearningRate>
    </Experiment>
    <Experiment id="l_iris_pca">
        <!-- Training set: 98.00% -->
        <!-- Cross-validation: 98.00% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <Iterations>400</Iterations>
        <LearningRate>0.1</LearningRate>
    </Experiment>
    <Experiment id="l_iris_test">
        <!-- Training set: 97.50% -->
        <!-- Test set: 96.67% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <Iterations>500</Iterations>
        <LearningRate>0.1</LearningRate>
    </Experiment>
    <Experiment id="l_iris_2d">
        <!-- Training set: 96.00% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/iris.2d.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.2</LearningRate>
    </Experiment>
    <Experiment id="l_flame">
        <!-- Training set: 71.25% -->
        <!-- Cross-validation: 70.42% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <Iterations>200</Iterations>
        <LearningRate>0.5</LearningRate>
    </Experiment>
    <Experiment id="l_moons">
        <!-- Training set: 87.94% -->
        <!-- Cross-validation: 87.94% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <Iterations>200</Iterations>
        <LearningRate>0.5</LearningRate>
    </Experiment>
    <Experiment id="l_diabetes">
        <!-- Training set: 77.99% -->
        <!-- Cross-validation: 77.60% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <Iterations>1500</Iterations>
        <LearningRate>0.2</LearningRate>
        <UseRegularization>false</UseRegularization>
        <Normalization>-1:1</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="l_diabetes_pca">
        <!-- Training set: 75.26% -->
        <!-- Cross-validation: 74.74% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/diabetes_pca.csv</TrainingData>
        <Iterations>2000</Iterations>
        <LearningRate>0.2</LearningRate>
        <Normalization>-2:2</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="l_glass">
        <!-- Training set: 60.28% -->
        <!-- Cross-validation: 56.54% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <Iterations>500</Iterations>
        <LearningRate>0.1</LearningRate>
        <Normalization>0:2</Normalization>
    </Experiment>
    <Experiment id="l_mnist">
        <!-- Training set: 91.44% -->
        <!-- Test set: 91.58% -->
        <!-- Cross-validation: 90.98% -->
        <Classifier>Linear</Classifier>
        <TrainingData>data_mnist/mnist_train.csv</TrainingData>
        <TestData>data_mnist/mnist_test.csv</TestData>
        <Iterations>1000</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <Normalization>0:1</Normalization>
        <BatchSize>100</BatchSize>
    </Experiment>
    <!--
        Neural Network Classifiers
        
        The following parameters are available:
        
        <Classifier>NN</Classifier>                             NN
        <TrainingData>data/demo.csv</TrainingData>              Path to training dataset
        <TestData></TestData>                                   Path to test dataset (or empty if no test data is used)
        <Iterations>10</Iterations>                             Training iterations (default is 200)
        <LearningRate>1.0</LearningRate>                        Learning rate (default is 1.0)
        <UseRegularization>true</UseRegularization>             Sets if regularization shall be used (default is true)
        <RegularizationStrength>0.001</RegularizationStrength>  Sets regularization strength (default is 0.001)
        <UseMomentum>true</UseMomentum>                         Sets if momentum shall be used (default is true)
        <HiddenLayers>16</HiddenLayers>                         Number of units in the hidden layer (default is 16)
        <Normalization>0:1</Normalization>                      Lower and upper bound for normalized values
        <BatchSize>100</BatchSize>                              Size of batches for batch training. If not set, batch training isn't used
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="nn_demo">
        <!-- Training set: 100.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <Iterations>20</Iterations>
        <LearningRate>1.0</LearningRate>
        <HiddenLayers>8</HiddenLayers>
    </Experiment>
    <Experiment id="nn_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 97.33% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <Iterations>2000</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>72</HiddenLayers>
        <BatchSize>100</BatchSize>
    </Experiment>
    <Experiment id="nn_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 100.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <Iterations>100</Iterations>
        <LearningRate>1.0</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>16</HiddenLayers>
    </Experiment>
    <Experiment id="nn_iris">
        <!-- Training set: 98.00% -->
        <!-- Cross-validation: 97.33% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <Iterations>1500</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>8</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>100</BatchSize>
    </Experiment>
    <Experiment id="nn_iris_test">
        <!-- Training set: 99.17% -->
        <!-- Test set: 96.67% -->
        <!-- Cross-validation: 98.33% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <Iterations>500</Iterations>
        <LearningRate>1.0</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>2</HiddenLayers>
        <Normalization>-1:1</Normalization>
    </Experiment>
    <Experiment id="nn_iris_2d">
        <!-- Training set: 96.00% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris.2D.csv</TrainingData>
        <Iterations>500</Iterations>
        <LearningRate>0.04</LearningRate>
        <HiddenLayers>4</HiddenLayers>
    </Experiment>
    <Experiment id="nn_iris_pca">
        <!-- Training set: 97.33% -->
        <!-- Cross-validation: 97.33% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <Iterations>500</Iterations>
        <LearningRate>0.2</LearningRate>
        <HiddenLayers>16</HiddenLayers>
    </Experiment>
    <Experiment id="nn_flame">
        <!-- Training set: 99.17% -->
        <!-- Cross-validation: 99.17% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <Iterations>500</Iterations>
        <LearningRate>0.5</LearningRate>
        <HiddenLayers>16</HiddenLayers>
    </Experiment>
    <Experiment id="nn_moons">
        <!-- Training set: 95.98% -->
        <!-- Cross-validation: 95.71% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.8</LearningRate>
        <HiddenLayers>16</HiddenLayers>
    </Experiment>
    <Experiment id="nn_diabetes">
        <!-- Training set: 79.95% -->
        <!-- Cross-validation: 78.12% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <Iterations>2000</Iterations>
        <LearningRate>0.2</LearningRate>
        <UseRegularization>true</UseRegularization>
        <HiddenLayers>72</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="nn_diabetes_pca">
        <!-- Training set: 75.65% -->
        <!-- Cross-validation: 73.83% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/diabetes_pca.csv</TrainingData>
        <Iterations>4000</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>8</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="nn_glass">
        <!-- Training set: 91.12% -->
        <!-- Cross-validation: 71.96% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <Iterations>6000</Iterations>
        <LearningRate>0.9</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>72</HiddenLayers>
        <Normalization>0:2</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="nn_mnist">
        <!-- Training set: 96.59% -->
        <!-- Test set: 95.84% -->
        <!-- Cross-validation: 95.50% -->
        <Classifier>NN</Classifier>
        <TrainingData>data_mnist/mnist_train.csv</TrainingData>
        <TestData>data_mnist/mnist_test.csv</TestData>
        <Iterations>2000</Iterations>
        <LearningRate>0.3</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>32</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>200</BatchSize>
    </Experiment>
    <!--
        Deep Neural Network Classifiers
        
        The following parameters are available:
        
        <Classifier>NN</Classifier>                             NN
        <TrainingData>data/demo.csv</TrainingData>              Path to training dataset
        <TestData></TestData>                                   Path to test dataset (or empty if no test data is used)
        <Iterations>10</Iterations>                             Training iterations (default is 200)
        <LearningRate>1.0</LearningRate>                        Learning rate (default is 1.0)
        <UseRegularization>true</UseRegularization>             Sets if regularization shall be used (default is true)
        <RegularizationStrength>0.001</RegularizationStrength>  Sets regularization strength (default is 0.001)
        <UseMomentum>true</UseMomentum>                         Sets if momentum shall be used (default is true)
        <HiddenLayers>16,8</HiddenLayers>                       Number of units in the hidden layers (default is 16)
        <Normalization>0:1</Normalization>                      Lower and upper bound for normalized values
        <BatchSize>100</BatchSize>                              Size of batches for batch training. If not set, batch training isn't used
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="dnn_demo">
        <!-- Training set: 100.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <Iterations>100</Iterations>
        <LearningRate>1.0</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>8,8</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 97.67% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.1</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>42,24</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 100.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <Iterations>200</Iterations>
        <LearningRate>1.0</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>12,8</HiddenLayers>
        <Normalization>-1:1</Normalization>
    </Experiment>
    <Experiment id="dnn_iris">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>8,4</HiddenLayers>
        <Normalization>-1:1</Normalization>
    </Experiment>
    <Experiment id="dnn_iris_test">
        <!-- Training set: 100.00% -->
        <!-- Test set: 96.67% -->
        <!-- Cross-validation: 95.83% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <Iterations>1500</Iterations>
        <LearningRate>0.6</LearningRate>
        <HiddenLayers>8,4</HiddenLayers>
        <Normalization>-1:1</Normalization>
    </Experiment>
    <Experiment id="dnn_iris_2d">
        <!-- Training set: 96.00% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris.2D.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.06</LearningRate>
        <HiddenLayers>16,8</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_iris_pca">
        <!-- Training set: 97.33% -->
        <!-- Cross-validation: 98.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.02</LearningRate>
        <HiddenLayers>32,16</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_flame">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.75% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <Iterations>500</Iterations>
        <LearningRate>0.4</LearningRate>
        <HiddenLayers>12,8</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_moons">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 100.00% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.7</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>16,12</HiddenLayers>
    </Experiment>
    <Experiment id="dnn_diabetes">
        <!-- Training set: 79.43% -->
        <!-- Cross-validation: 76.17% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <Iterations>1000</Iterations>
        <LearningRate>0.6</LearningRate>
        <HiddenLayers>16,8</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>50</BatchSize>
    </Experiment>
    <Experiment id="dnn_glass">
        <!-- Training set: 97.66% -->
        <!-- Cross-validation: 72.90% -->
        <Classifier>NN</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <Iterations>2000</Iterations>
        <LearningRate>0.4</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>64,32</HiddenLayers>
        <Normalization>-2:2</Normalization>
    </Experiment>
    <Experiment id="dnn_mnist">
        <!-- Training set: 97.05% -->
        <!-- Test set: 95.69% -->
        <!-- Cross-validation: 95.60% -->
        <Classifier>NN</Classifier>
        <TrainingData>data_mnist/mnist_train.csv</TrainingData>
        <TestData>data_mnist/mnist_test.csv</TestData>
        <Iterations>3000</Iterations>
        <LearningRate>0.3</LearningRate>
        <UseRegularization>false</UseRegularization>
        <HiddenLayers>32,16</HiddenLayers>
        <Normalization>0:1</Normalization>
        <BatchSize>200</BatchSize>
    </Experiment>
    <!--
        k-Nearest Neighbor Classifiers
        
        The following parameters are available:
        
        <Classifier>KNN</Classifier>                            KNN
        <TrainingData>data/demo.csv</TrainingData>              Path
        <TestData></TestData>                                   Path (or empty if no test data is used)
        <K>3</K>                                                Integer (default is 3)
        <DistanceMeasure>L2</DistanceMeasure>                   L1 or L2 (default is L2)
        <Normalization>0:1</Normalization>                      Lower and upper bound for normalized values
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="knn_demo">
        <!-- Training set: 100.00% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <K>2</K>
    </Experiment>
    <Experiment id="knn_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 98.33% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <K>3</K>
    </Experiment>
    <Experiment id="knn_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 100.00% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <K>3</K>
    </Experiment>
    <Experiment id="knn_iris">
        <!-- Training set: 96.67% -->
        <!-- Cross-validation: 95.33% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <K>4</K>
    </Experiment>
    <Experiment id="knn_iris_test">
        <!-- Training set: 97.50% -->
        <!-- Test set: 96.67% -->
        <!-- Cross-validation: 95.83% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <K>4</K>
    </Experiment>
    <Experiment id="knn_iris_2d">
        <!-- Training set: 98.67% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/iris.2D.csv</TrainingData>
        <K>4</K>
    </Experiment>
    <Experiment id="knn_iris_pca">
        <!-- Training set: 98.67% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <K>4</K>
    </Experiment>
    <Experiment id="knn_flame">
        <!-- Training set: 99.58% -->
        <!-- Cross-validation: 98.33% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <K>3</K>
    </Experiment>
    <Experiment id="knn_moons">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 100.00% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <K>3</K>
    </Experiment>
    <Experiment id="knn_diabetes">
        <!-- Training set: 85.81% -->
        <!-- Cross-validation: 73.05% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <Normalization>-1:1</Normalization>
        <K>3</K>
    </Experiment>
    <Experiment id="knn_glass">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 72.43% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <K>2</K>
    </Experiment>
    <Experiment id="knn_mnist">
         <!-- Training set: 98.87% -->
        <!-- Test set: 97.17% -->
        <Classifier>KNN</Classifier>
        <TrainingData>data_mnist/mnist_train.csv</TrainingData>
        <TestData>data_mnist/mnist_test.csv</TestData>
        <K>3</K>
    </Experiment>
    <!--
        RBF (Radial-Basis Function) Kernel Classifiers
        
        The following parameters are available:
        
        <Classifier>RBF</Classifier>                            RBF
        <TrainingData>data/demo.csv</TrainingData>              Path
        <TestData></TestData>                                   Path (or empty if no test data is used)
        <Gamma>1.0</Gamma>                                      Gamma value for RBF kernel (decimal value, default is 3)
        <Normalization>0:1</Normalization>                      Lower and upper bound for normalized values
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="rbf_demo">
        <!-- Training set: 100.00% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <Gamma>1.0</Gamma>
    </Experiment>
    <Experiment id="rbf_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 97.00% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <Gamma>40.0</Gamma>
    </Experiment>
    <Experiment id="rbf_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 84.11% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <Gamma>130.0</Gamma>
    </Experiment>
    <Experiment id="rbf_iris">
        <!-- Training set: 96.67% -->
        <!-- Cross-validation: 94.00% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <Gamma>0.7</Gamma>
    </Experiment>
    <Experiment id="rbf_iris_test">
        <!-- Training set: 95.00% -->
        <!-- Test set: 100.00% -->
        <!-- Cross-validation: 92.50% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <Gamma>0.5</Gamma>
    </Experiment>
    <Experiment id="rbf_iris_2d">
        <!-- Training set: 97.33% -->
        <!-- Cross-validation: 97.33% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/iris.2D.csv</TrainingData>
        <Gamma>1.0</Gamma>
    </Experiment>
    <Experiment id="rbf_iris_pca">
        <!-- Training set: 96.00% -->
        <!-- Cross-validation: 94.67% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <Gamma>1.5</Gamma>
    </Experiment>
    <Experiment id="rbf_flame">
        <!-- Training set: 98.33% -->
        <!-- Cross-validation: 88.75% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <Gamma>1000.0</Gamma>
    </Experiment>
    <Experiment id="rbf_moons">
        <!-- Training set: 98.12% -->
        <!-- Cross-validation: 97.86% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <Gamma>55.0</Gamma>
    </Experiment>
    <Experiment id="rbf_diabetes">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 65.10% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <Normalization>0:2</Normalization>
        <Gamma>100</Gamma>
    </Experiment>
    <Experiment id="rbf_glass">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 46.26% -->
        <Classifier>RBF</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <Normalization>0:2</Normalization>
        <Gamma>200.0</Gamma>
    </Experiment>
    <!--
        CART Tree Classifiers
        
        The following parameters are available:
        
        <Classifier>CART</Classifier>                           CART
        <TrainingData>data/demo.csv</TrainingData>              Path
        <TestData></TestData>                                   Path (or empty if no test data is used)
        <MaxDepth>5</MaxDepth>                                  Max depth of the tree (decimal value, default is 5)
        <MinSize>10</MinSize>                                   Minimum size of dataset for a split (decimal value, default is 10)
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
    -->
    <Experiment id="c_demo">
        <!-- Training set: 100.00% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <MaxDepth>2</MaxDepth>
        <MinSize>1</MinSize>
    </Experiment>
    <Experiment id="c_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 94.33% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.06% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>20</MinSize>
    </Experiment>
    <Experiment id="c_iris">
        <!-- Training set: 98.67% -->
        <!-- Cross-validation: 94.00% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_iris_pca">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>10</MinSize>
    </Experiment>
    <Experiment id="c_iris_svd">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/iris_svd.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>10</MinSize>
    </Experiment>
    <Experiment id="c_iris_test">
        <!-- Training set: 97.50% -->
        <!-- Test set: 96.67% -->
        <!-- Cross-validation: 92.50% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_iris_2d">
        <!-- Training set: 98.67% -->
        <!-- Cross-validation: 94.67% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/iris.2d.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_flame">
        <!-- Training set: 99.17% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_moons">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.93% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_diabetes">
        <!-- Training set: 83.46% -->
        <!-- Cross-validation: 75.65% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>10</MinSize>
    </Experiment>
    <Experiment id="c_diabetes_pca">
        <!-- Training set: 78.26% -->
        <!-- Cross-validation: 69.27% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/diabetes_pca.csv</TrainingData>
        <MaxDepth>4</MaxDepth>
        <MinSize>10</MinSize>
    </Experiment>
    <Experiment id="c_glass">
        <!-- Training set: 87.85% -->
        <!-- Cross-validation: 66.82% -->
        <Classifier>CART</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>5</MinSize>
    </Experiment>
    <Experiment id="c_mnist">
        <!-- Training set: 0.00% -->
        <!-- Test set: 0.00% -->
        <!-- Cross-validation: 0.00% -->
        <Classifier>CART</Classifier>
        <TrainingData>data_mnist/mnist_train.csv</TrainingData>
        <TestData>data_mnist/mnist_test.csv</TestData>
        <MaxDepth>5</MaxDepth>
        <MinSize>10</MinSize>
    </Experiment>
    <!--
        Random Forest Classifiers
        
        The following parameters are available:
        
        <Classifier>RF</Classifier>                             RF
        <TrainingData>data/demo.csv</TrainingData>              Path
        <TestData></TestData>                                   Path (or empty if no test data is used)
        <MaxDepth>5</MaxDepth>                                  Max depth of the tree (decimal value, default is 5)
        <MinSize>10</MinSize>                                   Minimum size of dataset for a split (decimal value, default is 10)
        <ShuffleData>true</ShuffleData>                         Sets if dataset shall be shuffle (default is true)
        <Trees>7</Trees>                                       Number of trees in the forest (default is 7)
        <SampleSize>0.9</SampleSize>                            Sample size of data subset for each tree (default is 0.9) 
    -->
    
    <Experiment id="rf_demo">
        <!-- Training set: 100.00% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/demo.csv</TrainingData>
        <MaxDepth>2</MaxDepth>
        <MinSize>1</MinSize>
        <Trees>3</Trees>
        <SampleSize>0.8</SampleSize>
    </Experiment>
    <Experiment id="rf_spiral">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 96.00% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/spiral.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>11</Trees>
    </Experiment>
    <Experiment id="rf_circle">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.45% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/circle.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>7</Trees>
    </Experiment>
    <Experiment id="rf_iris">
        <!-- Training set: 97.33% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/iris.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>11</Trees>
    </Experiment>
    <Experiment id="rf_iris_pca">
        <!-- Training set: 99.33% -->
        <!-- Cross-validation: 96.67% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/iris_pca.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>15</Trees>
    </Experiment>
    <Experiment id="rf_iris_test">
        <!-- Training set: 98.33% -->
        <!-- Test set: 100.00% -->
        <!-- Cross-validation: 95.00% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/iris_training.csv</TrainingData>
        <TestData>data/iris_test.csv</TestData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>15</Trees>
    </Experiment>
    <Experiment id="rf_iris_2d">
        <!-- Training set: 98.00% -->
        <!-- Cross-validation: 94.67% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/iris.2d.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>15</Trees>
    </Experiment>
    <Experiment id="rf_flame">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.75% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/flame.csv</TrainingData>
        <MaxDepth>6</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>19</Trees>
    </Experiment>
    <Experiment id="rf_moons">
        <!-- Training set: 100.00% -->
        <!-- Cross-validation: 98.12% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/moons.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>3</MinSize>
        <Trees>7</Trees>
    </Experiment>
    <Experiment id="rf_diabetes">
        <!-- Training set: 89.58% -->
        <!-- Cross-validation: 77.99% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/diabetes.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>10</MinSize>
        <Trees>19</Trees>
    </Experiment>
    <Experiment id="rf_diabetes_pca">
        <!-- Training set: 78.91% -->
        <!-- Cross-validation: 72.01% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/diabetes_pca.csv</TrainingData>
        <MaxDepth>5</MaxDepth>
        <MinSize>10</MinSize>
        <Trees>19</Trees>
    </Experiment>
    <Experiment id="rf_glass">
        <!-- Training set: 94.39% -->
        <!-- Cross-validation: 74.30% -->
        <Classifier>RF</Classifier>
        <TrainingData>data/glass.csv</TrainingData>
        <MaxDepth>7</MaxDepth>
        <MinSize>5</MinSize>
        <Trees>25</Trees>
    </Experiment>
</Experiments>